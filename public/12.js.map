{"version":3,"sources":["webpack:///./node_modules/@aws-amplify/ui-components/dist/esm-es5/amplify-chatbot.entry.js"],"names":[],"mappings":";;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iBAAiB,SAAI,IAAI,SAAI;AAC7B,2BAA2B,+DAA+D,gBAAgB,EAAE,EAAE;AAC9G;AACA,mCAAmC,MAAM,6BAA6B,EAAE,YAAY,WAAW,EAAE;AACjG,kCAAkC,MAAM,iCAAiC,EAAE,YAAY,WAAW,EAAE;AACpG,+BAA+B,qFAAqF;AACpH;AACA,KAAK;AACL;AACA,mBAAmB,SAAI,IAAI,SAAI;AAC/B,aAAa,6BAA6B,0BAA0B,aAAa,EAAE,qBAAqB;AACxG,gBAAgB,qDAAqD,oEAAoE,aAAa,EAAE;AACxJ,sBAAsB,sBAAsB,qBAAqB,GAAG;AACpE;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC,kCAAkC,SAAS;AAC3C,kCAAkC,WAAW,UAAU;AACvD,yCAAyC,cAAc;AACvD;AACA,6GAA6G,OAAO,UAAU;AAC9H,gFAAgF,iBAAiB,OAAO;AACxG,wDAAwD,gBAAgB,QAAQ,OAAO;AACvF,8CAA8C,gBAAgB,gBAAgB,OAAO;AACrF;AACA,iCAAiC;AACjC;AACA;AACA,SAAS,YAAY,aAAa,OAAO,EAAE,UAAU,WAAW;AAChE,mCAAmC,SAAS;AAC5C;AACA;AACA,sBAAsB,SAAI,IAAI,SAAI;AAClC,iDAAiD,QAAQ;AACzD,wCAAwC,QAAQ;AAChD,wDAAwD,QAAQ;AAChE;AACA;AACA;AAC6G;AAC7C;AACrC;AACoC;AACa;AACnB;AACzD;AACA;AACA;AACA,oBAAoB;AACpB,2BAA2B;AAC3B,2BAA2B;AAC3B,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,wBAAwB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,2CAA2C;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,kBAAkB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mBAAmB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC,qBAAqB;AACrB,iCAAiC;AACjC,gDAAgD;AAChD;AACA,gDAAgD;AAChD;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC,gDAAgD;AAChD,iCAAiC;AACjC;AACA,kCAAkC;AAClC,0CAA0C;AAC1C,gCAAgC;AAChC,gCAAgC;AAChC,+CAA+C;AAC/C,mDAAmD;AACnD,gCAAgC;AAChC,iCAAiC;AACjC;AACA,kCAAkC;AAClC,wCAAwC;AACxC,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA,qBAAqB,eAAe;AACpC,qBAAqB,OAAO;AAC5B,4BAA4B,OAAO;AACnC,4BAA4B,OAAO;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,iBAAiB,wDAAM;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,uEAAa;AAC1C;AACA;AACA;AACA,+CAA+C,cAAc;AAC7D;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA,yBAAyB,eAAe;AACxC,0BAA0B,WAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE;AACnE,qEAAqE;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,WAAW;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,cAAc;AAC5D;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,kBAAkB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,OAAO;AACvC;AACA;AACA,0CAA0C,+CAA+C;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,SAAS,uEAAa;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E;AAC3E;AACA;AACA;AACA,uBAAuB,iCAAiC;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,sCAAsC,WAAW,uCAAuC,cAAc,eAAe,mBAAmB,qBAAqB,eAAe,gBAAgB,oBAAoB,aAAa,oBAAoB,qDAAqD,6CAA6C,2BAA2B,mBAAmB,sBAAsB,qBAAqB,sBAAsB,4DAA4D,oDAAoD,6BAA6B,qBAAqB,qBAAqB,qDAAqD,6CAA6C,2BAA2B,mBAAmB,gCAAgC,GAAG,aAAa,SAAS,aAAa,wBAAwB,GAAG,aAAa,SAAS,aAAa,MAAM,iBAAiB,iBAAiB,8CAA8C,qCAAqC,0CAA0C,uBAAuB,sCAAsC,4CAA4C,uCAAuC,wCAAwC,iBAAiB,2BAA2B,oBAAoB,0BAA0B,sBAAsB,yCAAyC,uBAAuB,gEAAgE,wDAAwD,8BAA8B,sBAAsB,uCAAuC,mBAAmB,WAAW,qBAAqB,uBAAuB,0BAA0B,iBAAiB,oBAAoB,QAAQ,0CAA0C,0BAA0B,6BAA6B,iBAAiB,kBAAkB,qBAAqB,MAAM,+CAA+C,2BAA2B,oBAAoB,aAAa,oBAAoB,YAAY,0BAA0B,sBAAsB,cAAc,QAAQ,eAAe,oBAAoB,gBAAgB,qBAAqB,uBAAuB,KAAK,kBAAkB,6CAA6C,4BAA4B,qCAAqC,MAAM,iBAAiB,8CAA8C,6BAA6B,qCAAqC,QAAQ,oBAAoB,aAAa,sBAAsB,mBAAmB,8CAA8C,uBAAuB,oBAAoB,sBAAsB,cAAc,WAAW,oBAAoB,YAAY,OAAO,qBAAqB,sBAAsB,oBAAoB,YAAY,gBAAgB,aAAa,sBAAsB,yCAAyC,mBAAmB,aAAa;AACp8F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AAC/B;AACA;AACA;AACA;AACA;AACA,CAAC,kCAAkC;AACnC;AACA;AACA;AACA;AACA;AACA,CAAC,sCAAsC;AACvC;AACA;AACA;AACA,QAAQ,4DAAgB;AACxB;AACA;AACA;AACA;AACA;AACA,wBAAwB,2DAAY;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,QAAQ,4DAAC,SAAS,kCAAkC,mBAAmB,EAAE;AACxI;AACA;AACA;AACA,iCAAiC,4DAAC,SAAS,4BAA4B,EAAE,4DAAC,SAAS,kCAAkC,EAAE,4DAAC,UAAU,oBAAoB,GAAG,4DAAC,UAAU,sBAAsB,GAAG,4DAAC,UAAU,qBAAqB;AAC7N;AACA;AACA;AACA,6BAA6B,4DAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,sEAAY,WAAW,sEAAY;AAChD,4BAA4B,wDAA4B;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,2DAAY;AACtC;AACA;AACA;AACA,0BAA0B,2DAAY;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sEAAY;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,8BAA8B,EAAE,2BAA2B,uCAAuC,EAAE;AAC3J;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,sEAAY;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA,6CAA6C,sEAAY;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,uDAAuD,uDAAuD,EAAE;AAChH;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,4DAAC,YAAY,eAAe;AACxD,4BAA4B,4DAAC,oBAAoB,uEAAuE,mCAAmC,EAAE,sDAAsD;AACnN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,2DAAY;AAC1B,cAAc,2DAAY;AAC1B,yBAAyB,4DAAC,mBAAmB,cAAc,sDAAI,gFAAgF,oCAAoC,EAAE,uFAAuF;AAC5Q,8CAA8C,4DAAC,oBAAoB,oEAAoE,gCAAgC,EAAE,mJAAmJ;AAC5T,8CAA8C,4DAAC,oBAAoB,0HAA0H,gCAAgC,EAAE,wFAAwF;AACvT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAC,mBAAmB,UAAU,sDAAI,yCAAyC,0CAA0C,EAAE,EAAE;AACxI;AACA;AACA,gBAAgB,4DAAC,CAAC,oDAAI,QAAQ,4DAAC,SAAS,2BAA2B,EAAE,4DAAC,UAAU,iBAAiB,EAAE,4DAAC,SAAS,iDAAiD,EAAE,sDAAI,uBAAuB,4DAAC,SAAS,6CAA6C,mCAAmC,4DAAC,SAAS,iDAAiD;AAChV;AACA;AACA,0BAA0B,QAAQ,4DAAU,OAAO,EAAE;AACrD;AACA;AACA,KAAK;AACL;AACA,CAAC;AACD;AAC6C","file":"12.js","sourcesContent":["var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nvar __spreadArrays = (this && this.__spreadArrays) || function () {\n    for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\n    for (var r = Array(s), k = 0, i = 0; i < il; i++)\n        for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\n            r[k] = a[j];\n    return r;\n};\nimport { r as registerInstance, h, c as createEvent, H as Host, g as getElement } from './index-3fb5c139.js';\nimport { Logger, browserOrNode, I18n } from '@aws-amplify/core';\nimport '@aws-amplify/auth';\nimport { T as Translations } from './Translations-c833f663.js';\nimport { d as NO_INTERACTIONS_MODULE_FOUND } from './constants-d1abe7de.js';\nimport { Interactions } from '@aws-amplify/interactions';\n// AudioRecorder settings\nvar RECORDER_EXPORT_MIME_TYPE = 'application/octet-stream';\nvar DEFAULT_EXPORT_SAMPLE_RATE = 16000;\nvar FFT_SIZE = 2048; // window size in samples for Fast Fourier Transform (FFT)\nvar FFT_MAX_DECIBELS = -10; // maximum power value in the scaling range for the FFT analysis data\nvar FFT_MIN_DECIBELS = -90; // minimum power value in the scaling range for the FFT analysis data\nvar FFT_SMOOTHING_TIME_CONSTANT = 0.85; // averaging constant with the last analysis frame\n/**\n * Merges multiple buffers into one.\n */\nvar mergeBuffers = function (bufferArray, recLength) {\n    var result = new Float32Array(recLength);\n    var offset = 0;\n    for (var i = 0; i < bufferArray.length; i++) {\n        result.set(bufferArray[i], offset);\n        offset += bufferArray[i].length;\n    }\n    return result;\n};\n/**\n * Downsamples audio to desired export sample rate.\n */\nvar downsampleBuffer = function (buffer, recordSampleRate, exportSampleRate) {\n    if (exportSampleRate === recordSampleRate) {\n        return buffer;\n    }\n    var sampleRateRatio = recordSampleRate / exportSampleRate;\n    var newLength = Math.round(buffer.length / sampleRateRatio);\n    var result = new Float32Array(newLength);\n    var offsetResult = 0;\n    var offsetBuffer = 0;\n    while (offsetResult < result.length) {\n        var nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);\n        var accum = 0, count = 0;\n        for (var i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {\n            accum += buffer[i];\n            count++;\n        }\n        result[offsetResult] = accum / count;\n        offsetResult++;\n        offsetBuffer = nextOffsetBuffer;\n    }\n    return result;\n};\n/**\n * converts raw audio values to 16 bit pcm.\n */\nvar floatTo16BitPCM = function (output, offset, input) {\n    var byteOffset = offset;\n    for (var i = 0; i < input.length; i++, byteOffset += 2) {\n        var s = Math.max(-1, Math.min(1, input[i]));\n        output.setInt16(byteOffset, s < 0 ? s * 0x8000 : s * 0x7fff, true);\n    }\n};\n/**\n * Write given strings in big-endian order.\n */\nvar writeString = function (view, offset, string) {\n    for (var i = 0; i < string.length; i++) {\n        view.setUint8(offset + i, string.charCodeAt(i));\n    }\n};\n/**\n * Encodes raw pcm audio into a wav file.\n */\nvar encodeWAV = function (samples, exportSampleRate) {\n    /**\n     * WAV file consists of three parts: RIFF header, WAVE subchunk, and data subchunk. We precompute the size of them.\n     */\n    var audioSize = samples.length * 2; // We use 16-bit samples, so we have (2 * sampleLength) bytes.\n    var fmtSize = 24; // Byte size of the fmt subchunk: 24 bytes that the audio information that we'll set below.\n    var dataSize = 8 + audioSize; // Byte size of the data subchunk: raw sound data plus 8 bytes for the subchunk descriptions.\n    var totalByteSize = 12 + fmtSize + dataSize; // Byte size of the whole file, including the chunk header / descriptor.\n    // create DataView object to write byte values into\n    var buffer = new ArrayBuffer(totalByteSize); // buffer to write the chunk values in.\n    var view = new DataView(buffer);\n    /**\n     * Start writing the .wav file. We write top to bottom, so byte offset (first numeric argument) increases strictly.\n     */\n    // RIFF header\n    writeString(view, 0, 'RIFF'); // At offset 0, write the letters \"RIFF\"\n    view.setUint32(4, fmtSize + dataSize, true); // At offset 4, write the size of fmt and data chunk size combined.\n    writeString(view, 8, 'WAVE'); // At offset 8, write the format type \"WAVE\"\n    // fmt subchunk\n    writeString(view, 12, 'fmt '); //chunkdId 'fmt '\n    view.setUint32(16, fmtSize - 8, true); // fmt subchunk size below this value. We set 8 bytes already, so subtract 8 bytes from fmtSize.\n    view.setUint16(20, 1, true); // Audio format code, which is 1 for PCM.\n    view.setUint16(22, 1, true); // Number of audio channels. We use mono, ie 1.\n    view.setUint32(24, exportSampleRate, true); // Sample rate of the audio file.\n    view.setUint32(28, exportSampleRate * 2, true); // Data rate, or # of data bytes per second. Since each sample is 2 bytes, this is 2 * sampleRate.\n    view.setUint16(32, 2, true); // block align, # of bytes per sample including all channels, ie. 2 bytes.\n    view.setUint16(34, 16, true); // bits per sample, ie. 16 bits\n    // data subchunk\n    writeString(view, 36, 'data'); // write the chunkId 'data'\n    view.setUint32(40, audioSize, true); // Audio byte size\n    floatTo16BitPCM(view, 44, samples); // raw pcm values then go here.\n    return view;\n};\n/**\n * Given arrays of raw pcm audio, downsamples the audio to desired sample rate and encodes it to a wav audio file.\n *\n * @param recBuffer {Float32Array[]} - 2d float array containing the recorded raw audio\n * @param recLength {number} - total length of recorded audio\n * @param recordSampleRate {number} - sample rate of the recorded audio\n * @param exportSampleRate {number} - desired sample rate of the exported file\n */\nvar exportBuffer = function (recBuffer, recLength, recordSampleRate, exportSampleRate) {\n    var mergedBuffers = mergeBuffers(recBuffer, recLength);\n    var downsampledBuffer = downsampleBuffer(mergedBuffers, recordSampleRate, exportSampleRate);\n    var encodedWav = encodeWAV(downsampledBuffer, exportSampleRate);\n    var audioBlob = new Blob([encodedWav], {\n        type: RECORDER_EXPORT_MIME_TYPE,\n    });\n    return audioBlob;\n};\nvar logger = new Logger('AudioRecorder');\nvar AudioRecorder = /** @class */ (function () {\n    function AudioRecorder(options) {\n        // input mic stream is stored in a buffer\n        this.streamBuffer = [];\n        this.streamBufferLength = 0;\n        this.recording = false;\n        this.options = options;\n    }\n    /**\n     * This must be called first to enable audio context and request microphone access.\n     * Once access granted, it connects all the necessary audio nodes to the context so that it can begin recording or playing.\n     */\n    AudioRecorder.prototype.init = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (!browserOrNode().isBrowser) return [3 /*break*/, 2];\n                        window.AudioContext = window.AudioContext || window.webkitAudioContext;\n                        this.audioContext = new AudioContext();\n                        return [4 /*yield*/, navigator.mediaDevices\n                                .getUserMedia({ audio: true })\n                                .then(function (stream) {\n                                _this.audioSupported = true;\n                                _this.setupAudioNodes(stream);\n                            })\n                                .catch(function () {\n                                _this.audioSupported = false;\n                                return Promise.reject('Audio is not supported');\n                            })];\n                    case 1:\n                        _a.sent();\n                        return [3 /*break*/, 3];\n                    case 2:\n                        this.audioSupported = false;\n                        return [2 /*return*/, Promise.reject('Audio is not supported')];\n                    case 3: return [2 /*return*/];\n                }\n            });\n        });\n    };\n    /**\n     * Setup audio nodes after successful `init`.\n     */\n    AudioRecorder.prototype.setupAudioNodes = function (stream) {\n        return __awaiter(this, void 0, void 0, function () {\n            var err_1, sourceNode, processorNode, analyserNode;\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        _a.trys.push([0, 2, , 3]);\n                        return [4 /*yield*/, this.audioContext.resume()];\n                    case 1:\n                        _a.sent();\n                        return [3 /*break*/, 3];\n                    case 2:\n                        err_1 = _a.sent();\n                        logger.error(err_1);\n                        return [3 /*break*/, 3];\n                    case 3:\n                        sourceNode = this.audioContext.createMediaStreamSource(stream);\n                        processorNode = this.audioContext.createScriptProcessor(4096, 1, 1);\n                        processorNode.onaudioprocess = function (audioProcessingEvent) {\n                            if (!_this.recording)\n                                return;\n                            var stream = audioProcessingEvent.inputBuffer.getChannelData(0);\n                            _this.streamBuffer.push(new Float32Array(stream)); // set to a copy of the stream\n                            _this.streamBufferLength += stream.length;\n                            _this.analyse();\n                        };\n                        analyserNode = this.audioContext.createAnalyser();\n                        analyserNode.minDecibels = FFT_MIN_DECIBELS;\n                        analyserNode.maxDecibels = FFT_MAX_DECIBELS;\n                        analyserNode.smoothingTimeConstant = FFT_SMOOTHING_TIME_CONSTANT;\n                        sourceNode.connect(analyserNode);\n                        analyserNode.connect(processorNode);\n                        processorNode.connect(sourceNode.context.destination);\n                        this.analyserNode = analyserNode;\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    /**\n     * Start recording audio and listen for silence.\n     *\n     * @param onSilence {SilenceHandler} - called whenever silence is detected\n     * @param visualizer {Visualizer} - called with audio data on each audio process to be used for visualization.\n     */\n    AudioRecorder.prototype.startRecording = function (onSilence, visualizer) {\n        return __awaiter(this, void 0, void 0, function () {\n            var context, err_2;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (this.recording || !this.audioSupported)\n                            return [2 /*return*/];\n                        this.onSilence = onSilence || function () { };\n                        this.visualizer = visualizer || function () { };\n                        context = this.audioContext;\n                        _a.label = 1;\n                    case 1:\n                        _a.trys.push([1, 3, , 4]);\n                        return [4 /*yield*/, context.resume()];\n                    case 2:\n                        _a.sent();\n                        return [3 /*break*/, 4];\n                    case 3:\n                        err_2 = _a.sent();\n                        logger.error(err_2);\n                        return [3 /*break*/, 4];\n                    case 4:\n                        this.start = Date.now();\n                        this.recording = true;\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    /**\n     * Pause recording\n     */\n    AudioRecorder.prototype.stopRecording = function () {\n        if (!this.audioSupported)\n            return;\n        this.recording = false;\n    };\n    /**\n     * Pause recording and clear audio buffer\n     */\n    AudioRecorder.prototype.clear = function () {\n        this.stopRecording();\n        this.streamBufferLength = 0;\n        this.streamBuffer = [];\n    };\n    /**\n     * Plays given audioStream with audioContext\n     *\n     * @param buffer {Uint8Array} - audioStream to be played\n     */\n    AudioRecorder.prototype.play = function (buffer) {\n        var _this = this;\n        if (!buffer || !this.audioSupported)\n            return;\n        var myBlob = new Blob([buffer]);\n        return new Promise(function (res, rej) {\n            var fileReader = new FileReader();\n            fileReader.onload = function () {\n                if (_this.playbackSource)\n                    _this.playbackSource.disconnect(); // disconnect previous playback source\n                _this.playbackSource = _this.audioContext.createBufferSource();\n                var successCallback = function (buf) {\n                    _this.playbackSource.buffer = buf;\n                    _this.playbackSource.connect(_this.audioContext.destination);\n                    _this.playbackSource.onended = function () {\n                        return res();\n                    };\n                    _this.playbackSource.start(0);\n                };\n                var errorCallback = function (err) {\n                    return rej(err);\n                };\n                _this.audioContext.decodeAudioData(fileReader.result, successCallback, errorCallback);\n            };\n            fileReader.onerror = function () { return rej(); };\n            fileReader.readAsArrayBuffer(myBlob);\n        });\n    };\n    /**\n     * Stops playing audio if there's a playback source connected.\n     */\n    AudioRecorder.prototype.stop = function () {\n        if (this.playbackSource) {\n            this.playbackSource.stop();\n        }\n    };\n    /**\n     * Called after each audioProcess. Check for silence and give fft time domain data to visualizer.\n     */\n    AudioRecorder.prototype.analyse = function () {\n        if (!this.audioSupported)\n            return;\n        var analyser = this.analyserNode;\n        analyser.fftSize = FFT_SIZE;\n        var bufferLength = analyser.fftSize;\n        var dataArray = new Uint8Array(bufferLength);\n        var amplitude = this.options.amplitude;\n        var time = this.options.time;\n        analyser.getByteTimeDomainData(dataArray);\n        this.visualizer(dataArray, bufferLength);\n        for (var i = 0; i < bufferLength; i++) {\n            // Normalize between -1 and 1.\n            var curr_value_time = dataArray[i] / 128 - 1.0;\n            if (curr_value_time > amplitude || curr_value_time < -1 * amplitude) {\n                this.start = Date.now();\n            }\n        }\n        var newtime = Date.now();\n        var elapsedTime = newtime - this.start;\n        if (elapsedTime > time) {\n            this.onSilence();\n        }\n    };\n    /**\n     * Encodes recorded buffer to a wav file and exports it to a blob.\n     *\n     * @param exportSampleRate {number} - desired sample rate of the exported buffer\n     */\n    AudioRecorder.prototype.exportWAV = function (exportSampleRate) {\n        if (exportSampleRate === void 0) { exportSampleRate = DEFAULT_EXPORT_SAMPLE_RATE; }\n        return __awaiter(this, void 0, void 0, function () {\n            var recordSampleRate, blob;\n            return __generator(this, function (_a) {\n                if (!this.audioSupported)\n                    return [2 /*return*/];\n                recordSampleRate = this.audioContext.sampleRate;\n                blob = exportBuffer(this.streamBuffer, this.streamBufferLength, recordSampleRate, exportSampleRate);\n                this.clear();\n                return [2 /*return*/, blob];\n            });\n        });\n    };\n    return AudioRecorder;\n}());\nvar visualize = function (dataArray, bufferLength, canvas) {\n    if (!canvas)\n        return;\n    if (!browserOrNode().isBrowser)\n        throw new Error('Visualization is not supported on non-browsers.');\n    var _a = canvas.getBoundingClientRect(), width = _a.width, height = _a.height;\n    // need to update the default canvas width and height\n    canvas.width = width;\n    canvas.height = height;\n    var canvasCtx = canvas.getContext('2d');\n    canvasCtx.fillStyle = 'white';\n    canvasCtx.clearRect(0, 0, width, height);\n    var draw = function () {\n        canvasCtx.fillRect(0, 0, width, height);\n        canvasCtx.lineWidth = 1;\n        var color = getComputedStyle(document.documentElement).getPropertyValue('--amplify-primary-color');\n        canvasCtx.strokeStyle = !color || color === '' ? '#ff9900' : color; // TODO: try separate css variable\n        canvasCtx.beginPath();\n        var sliceWidth = (width * 1.0) / bufferLength;\n        var x = 0;\n        for (var i = 0; i < bufferLength || i % 3 === 0; i++) {\n            var value = dataArray[i] / 128.0;\n            var y = (value * height) / 2;\n            if (i === 0) {\n                canvasCtx.moveTo(x, y);\n            }\n            else {\n                canvasCtx.lineTo(x, y);\n            }\n            x += sliceWidth;\n        }\n        canvasCtx.lineTo(canvas.width, canvas.height / 2);\n        canvasCtx.stroke();\n    };\n    // Register our draw function with requestAnimationFrame.\n    requestAnimationFrame(draw);\n};\nvar amplifyChatbotCss = \".bot .dot{background-color:var(--bot-dot-color)}.user .dot{background-color:var(--user-dot-color)}.dot-flashing{width:2.625rem}.dot-flashing .dot{display:inline-block;width:0.625rem;height:0.625rem;border-radius:10rem;opacity:0.65}.dot-flashing .left{-webkit-animation:dot-flashing 1s infinite alternate;animation:dot-flashing 1s infinite alternate;-webkit-animation-delay:0s;animation-delay:0s}.dot-flashing .middle{margin-left:0.375rem;margin-right:0.375rem;-webkit-animation:dot-flashing 1s infinite linear alternate;animation:dot-flashing 1s infinite linear alternate;-webkit-animation-delay:0.5s;animation-delay:0.5s}.dot-flashing .right{-webkit-animation:dot-flashing 1s infinite alternate;animation:dot-flashing 1s infinite alternate;-webkit-animation-delay:1s;animation-delay:1s}@-webkit-keyframes dot-flashing{0%{opacity:0.65}50%,100%{opacity:0.1}}@keyframes dot-flashing{0%{opacity:0.65}50%,100%{opacity:0.1}}:host{--width:28.75rem;--height:37.5rem;--header-color:var(--amplify-secondary-color);--header-size:var(--amplify-text-lg);--bot-background-color:rgb(230, 230, 230);--bot-text-color:black;--bot-dot-color:var(--bot-text-color);--user-background-color:var(--amplify-blue);--user-text-color:var(--amplify-white);--user-dot-color:var(--user-text-color)}.amplify-chatbot{display:-ms-inline-flexbox;display:inline-flex;-ms-flex-direction:column;flex-direction:column;background-color:var(--background-color);border-radius:0.375rem;-webkit-box-shadow:0.0625rem 0rem 0.25rem 0 rgba(0, 0, 0, 0.15);box-shadow:0.0625rem 0rem 0.25rem 0 rgba(0, 0, 0, 0.15);-webkit-box-sizing:border-box;box-sizing:border-box;font-family:var(--amplify-font-family);margin-bottom:1rem;width:100%;height:var(--height);max-width:var(--width)}@media (min-width: 672px){.amplify-chatbot{width:var(--width)}}.header{padding:1.25rem 0.375rem 1.25rem 0.375rem;color:var(--header-color);font-size:var(--header-size);font-weight:bold;text-align:center;word-wrap:break-word}.body{border-top:0.0625rem solid rgba(0, 0, 0, 0.05);padding:1.5rem 1rem 0 1rem;display:-ms-flexbox;display:flex;-ms-flex-positive:1;flex-grow:1;-ms-flex-direction:column;flex-direction:column;overflow:auto}.bubble{max-width:100%;padding:0.8em 1.4em;text-align:left;word-wrap:break-word;margin-bottom:0.625rem}.bot{margin-right:auto;background-color:var(--bot-background-color);color:var(--bot-text-color);border-radius:1.5rem 1.5rem 1.5rem 0}.user{margin-left:auto;background-color:var(--user-background-color);color:var(--user-text-color);border-radius:1.5rem 1.5rem 0 1.5rem}.footer{display:-ms-flexbox;display:flex;-ms-flex-align:center;align-items:center;border-top:0.062rem solid rgba(0, 0, 0, 0.05);padding-right:0.625rem;min-height:3.125rem}.footer amplify-input{--border:none;--margin:0;-ms-flex-positive:1;flex-grow:1}canvas{margin-left:0.625rem;margin-right:0.625rem;-ms-flex-positive:1;flex-grow:1;height:3.125rem}.icon-button{--icon-height:1.25rem;--icon-fill:var(--amplify-primary-color);--padding:0.625rem;--width:auto}\";\n// enum for possible bot states\nvar ChatState;\n(function (ChatState) {\n    ChatState[ChatState[\"Initial\"] = 0] = \"Initial\";\n    ChatState[ChatState[\"Listening\"] = 1] = \"Listening\";\n    ChatState[ChatState[\"SendingText\"] = 2] = \"SendingText\";\n    ChatState[ChatState[\"SendingVoice\"] = 3] = \"SendingVoice\";\n    ChatState[ChatState[\"Error\"] = 4] = \"Error\";\n})(ChatState || (ChatState = {}));\n// Message types\nvar MessageFrom;\n(function (MessageFrom) {\n    MessageFrom[\"Bot\"] = \"bot\";\n    MessageFrom[\"User\"] = \"user\";\n})(MessageFrom || (MessageFrom = {}));\n// Error types\nvar ChatErrorType;\n(function (ChatErrorType) {\n    ChatErrorType[ChatErrorType[\"Recoverable\"] = 0] = \"Recoverable\";\n    ChatErrorType[ChatErrorType[\"Unrecoverable\"] = 1] = \"Unrecoverable\";\n})(ChatErrorType || (ChatErrorType = {}));\nvar AmplifyChatbot = /** @class */ (function () {\n    function class_1(hostRef) {\n        var _this = this;\n        registerInstance(this, hostRef);\n        /** Clear messages when conversation finishes */\n        this.clearOnComplete = false;\n        /** Continue listening to users after they send the message */\n        this.conversationModeOn = false;\n        /** Text placed in the top header */\n        this.botTitle = Translations.CHATBOT_TITLE;\n        /** Whether voice chat is enabled */\n        this.voiceEnabled = false;\n        /** Whether text chat is enabled */\n        this.textEnabled = true;\n        /** Amount of silence (in ms) to wait for */\n        this.silenceTime = 1500;\n        /** Noise threshold between -1 and 1. Anything below is considered a silence. */\n        this.silenceThreshold = 0.2;\n        /** Messages in current session */\n        this.messages = [];\n        /** Text input box value  */\n        this.text = '';\n        /** Current app state */\n        this.chatState = ChatState.Initial;\n        /**\n         * Rendering methods\n         */\n        this.messageJSX = function (messages) {\n            var messageList = messages.map(function (message) { return h(\"div\", { class: \"bubble \" + message.from }, message.content); });\n            if (_this.chatState === ChatState.SendingText || _this.chatState === ChatState.SendingVoice) {\n                // if waiting for voice message, show animation on user side because app is waiting for transcript. Else put it on bot side.\n                var client = _this.chatState === ChatState.SendingText ? MessageFrom.Bot : MessageFrom.User;\n                messageList.push(h(\"div\", { class: \"bubble \" + client }, h(\"div\", { class: \"dot-flashing \" + client }, h(\"span\", { class: \"dot left\" }), h(\"span\", { class: \"dot middle\" }), h(\"span\", { class: \"dot right\" }))));\n            }\n            return messageList;\n        };\n        this.chatCompleted = createEvent(this, \"chatCompleted\", 7);\n    }\n    // Occurs when user presses enter in input box\n    class_1.prototype.submitHandler = function (_event) {\n        this.sendTextMessage();\n    };\n    /**\n     * Lifecycle functions\n     */\n    class_1.prototype.componentWillLoad = function () {\n        if (!Interactions || typeof Interactions.onComplete !== 'function') {\n            throw new Error(NO_INTERACTIONS_MODULE_FOUND);\n        }\n        this.validateProps();\n    };\n    class_1.prototype.componentDidRender = function () {\n        // scroll to the bottom if necessary\n        var body = this.element.shadowRoot.querySelector('.body');\n        body.scrollTop = body.scrollHeight;\n    };\n    class_1.prototype.validateProps = function () {\n        var _this = this;\n        if (!this.voiceEnabled && !this.textEnabled) {\n            this.setError(Translations.CHAT_DISABLED_ERROR, ChatErrorType.Unrecoverable);\n            return;\n        }\n        else if (!this.botName) {\n            this.setError(Translations.NO_BOT_NAME_ERROR, ChatErrorType.Unrecoverable);\n            return;\n        }\n        if (this.welcomeMessage)\n            this.appendToChat(this.welcomeMessage, MessageFrom.Bot);\n        // Initialize AudioRecorder if voice is enabled\n        if (this.voiceEnabled) {\n            this.audioRecorder = new AudioRecorder({\n                time: this.silenceTime,\n                amplitude: this.silenceThreshold,\n            });\n            this.audioRecorder.init().catch(function (err) {\n                _this.setError(err, ChatErrorType.Recoverable);\n            });\n        }\n        // Callback function to be called after chat is completed\n        var onComplete = function (err, data) {\n            _this.chatCompleted.emit({\n                data: data,\n                err: err,\n            });\n            if (_this.clearOnComplete) {\n                _this.reset();\n            }\n            else {\n                _this.chatState = ChatState.Initial;\n            }\n        };\n        try {\n            Interactions.onComplete(this.botName, onComplete);\n        }\n        catch (err) {\n            this.setError(err, ChatErrorType.Unrecoverable);\n        }\n    };\n    /**\n     * Handlers\n     */\n    class_1.prototype.handleMicButton = function () {\n        var _this = this;\n        if (this.chatState !== ChatState.Initial)\n            return;\n        this.audioRecorder.stop();\n        this.chatState = ChatState.Listening;\n        this.audioRecorder.startRecording(function () { return _this.handleSilence(); }, function (data, length) { return _this.visualizer(data, length); });\n    };\n    class_1.prototype.handleSilence = function () {\n        var _this = this;\n        this.chatState = ChatState.SendingVoice;\n        this.audioRecorder.stopRecording();\n        this.audioRecorder.exportWAV().then(function (blob) {\n            _this.sendVoiceMessage(blob);\n        });\n    };\n    class_1.prototype.handleTextChange = function (event) {\n        var target = event.target;\n        this.text = target.value;\n    };\n    class_1.prototype.handleCancelButton = function () {\n        this.audioRecorder.clear();\n        this.chatState = ChatState.Initial;\n    };\n    class_1.prototype.handleToastClose = function (errorType) {\n        this.error = undefined; // clear error\n        // if error is recoverable, reset the app state to initial\n        if (errorType === ChatErrorType.Recoverable) {\n            this.chatState = ChatState.Initial;\n        }\n    };\n    /**\n     * Visualization\n     */\n    class_1.prototype.visualizer = function (dataArray, bufferLength) {\n        var canvas = this.element.shadowRoot.querySelector('canvas');\n        visualize(dataArray, bufferLength, canvas);\n    };\n    /**\n     * Interactions helpers\n     */\n    class_1.prototype.sendTextMessage = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var text, response, err_3;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (this.text.length === 0 || this.chatState !== ChatState.Initial)\n                            return [2 /*return*/];\n                        text = this.text;\n                        this.text = '';\n                        this.appendToChat(text, MessageFrom.User);\n                        this.chatState = ChatState.SendingText;\n                        _a.label = 1;\n                    case 1:\n                        _a.trys.push([1, 3, , 4]);\n                        return [4 /*yield*/, Interactions.send(this.botName, text)];\n                    case 2:\n                        response = _a.sent();\n                        return [3 /*break*/, 4];\n                    case 3:\n                        err_3 = _a.sent();\n                        this.setError(err_3, ChatErrorType.Recoverable);\n                        return [2 /*return*/];\n                    case 4:\n                        if (response.message) {\n                            this.appendToChat(response.message, MessageFrom.Bot);\n                        }\n                        this.chatState = ChatState.Initial;\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    class_1.prototype.sendVoiceMessage = function (audioInput) {\n        return __awaiter(this, void 0, void 0, function () {\n            var interactionsMessage, response, err_4, dialogState;\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        interactionsMessage = {\n                            content: audioInput,\n                            options: {\n                                messageType: 'voice',\n                            },\n                        };\n                        _a.label = 1;\n                    case 1:\n                        _a.trys.push([1, 3, , 4]);\n                        return [4 /*yield*/, Interactions.send(this.botName, interactionsMessage)];\n                    case 2:\n                        response = _a.sent();\n                        return [3 /*break*/, 4];\n                    case 3:\n                        err_4 = _a.sent();\n                        this.setError(err_4, ChatErrorType.Recoverable);\n                        return [2 /*return*/];\n                    case 4:\n                        this.chatState = ChatState.Initial;\n                        dialogState = response.dialogState;\n                        if (response.inputTranscript)\n                            this.appendToChat(response.inputTranscript, MessageFrom.User);\n                        this.appendToChat(response.message, MessageFrom.Bot);\n                        return [4 /*yield*/, this.audioRecorder\n                                .play(response.audioStream)\n                                .then(function () {\n                                // if conversationMode is on, chat is incomplete, and mic button isn't pressed yet, resume listening.\n                                if (_this.conversationModeOn &&\n                                    dialogState !== 'Fulfilled' &&\n                                    dialogState !== 'Failed' &&\n                                    _this.chatState === ChatState.Initial) {\n                                    _this.handleMicButton();\n                                }\n                            })\n                                .catch(function (err) { return _this.setError(err, ChatErrorType.Recoverable); })];\n                    case 5:\n                        _a.sent();\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    class_1.prototype.appendToChat = function (content, from) {\n        this.messages = __spreadArrays(this.messages, [\n            {\n                content: content,\n                from: from,\n            },\n        ]);\n    };\n    /**\n     * State control methods\n     */\n    class_1.prototype.setError = function (error, errorType) {\n        var message = typeof error === 'string' ? error : error.message;\n        this.chatState = ChatState.Error;\n        this.error = { message: message, errorType: errorType };\n    };\n    class_1.prototype.reset = function () {\n        this.chatState = ChatState.Initial;\n        this.text = '';\n        this.error = undefined;\n        this.messages = [];\n        if (this.welcomeMessage)\n            this.appendToChat(this.welcomeMessage, MessageFrom.Bot);\n        this.audioRecorder && this.audioRecorder.clear();\n    };\n    class_1.prototype.listeningFooterJSX = function () {\n        var _this = this;\n        var visualization = h(\"canvas\", { height: \"50\" });\n        var cancelButton = (h(\"amplify-button\", { \"data-test\": \"chatbot-cancel-button\", handleButtonClick: function () { return _this.handleCancelButton(); }, class: \"icon-button\", variant: \"icon\", icon: \"ban\" }));\n        return [visualization, cancelButton];\n    };\n    class_1.prototype.footerJSX = function () {\n        var _this = this;\n        if (this.chatState === ChatState.Listening)\n            return this.listeningFooterJSX();\n        var inputPlaceholder = this.textEnabled\n            ? Translations.TEXT_INPUT_PLACEHOLDER\n            : Translations.VOICE_INPUT_PLACEHOLDER;\n        var textInput = (h(\"amplify-input\", { placeholder: I18n.get(inputPlaceholder), description: \"text\", handleInputChange: function (evt) { return _this.handleTextChange(evt); }, value: this.text, disabled: this.chatState === ChatState.Error || !this.textEnabled }));\n        var micButton = this.voiceEnabled && (h(\"amplify-button\", { \"data-test\": \"chatbot-mic-button\", handleButtonClick: function () { return _this.handleMicButton(); }, class: \"icon-button\", variant: \"icon\", icon: \"microphone\", disabled: this.chatState === ChatState.Error || this.chatState !== ChatState.Initial }));\n        var sendButton = this.textEnabled && (h(\"amplify-button\", { \"data-test\": \"chatbot-send-button\", class: \"icon-button\", variant: \"icon\", icon: \"send\", handleButtonClick: function () { return _this.sendTextMessage(); }, disabled: this.chatState === ChatState.Error || this.chatState !== ChatState.Initial }));\n        return [textInput, micButton, sendButton];\n    };\n    class_1.prototype.errorToast = function () {\n        var _this = this;\n        if (!this.error)\n            return;\n        var _a = this.error, message = _a.message, errorType = _a.errorType;\n        return h(\"amplify-toast\", { message: I18n.get(message), handleClose: function () { return _this.handleToastClose(errorType); } });\n    };\n    class_1.prototype.render = function () {\n        return (h(Host, null, h(\"div\", { class: \"amplify-chatbot\" }, h(\"slot\", { name: \"header\" }, h(\"div\", { class: \"header\", \"data-test\": \"chatbot-header\" }, I18n.get(this.botTitle))), h(\"div\", { class: \"body\", \"data-test\": \"chatbot-body\" }, this.messageJSX(this.messages)), h(\"div\", { class: \"footer\", \"data-test\": \"chatbot-footer\" }, this.footerJSX()), this.errorToast())));\n    };\n    Object.defineProperty(class_1.prototype, \"element\", {\n        get: function () { return getElement(this); },\n        enumerable: false,\n        configurable: true\n    });\n    return class_1;\n}());\nAmplifyChatbot.style = amplifyChatbotCss;\nexport { AmplifyChatbot as amplify_chatbot };\n"],"sourceRoot":""}